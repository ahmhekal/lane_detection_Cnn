{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8baadca88ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Normalize labels - training images get normalized to start in the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0maugmented_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmented_labels\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" This file contains code for a fully convolutional\n",
    "(i.e. contains zero fully connected layers) neural network\n",
    "for detecting lanes. This version assumes the inputs\n",
    "to be road images in the shape of 80 x 160 x 3 (RGB) with\n",
    "the labels as 80 x 160 x 1 (just the G channel with a\n",
    "re-drawn lane). Note that in order to view a returned image,\n",
    "the predictions is later stacked with zero'ed R and B layers\n",
    "and added back to the initial road image.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# Import necessary items from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "\n",
    "# Load training images\n",
    "train_images = pickle.load(open(\"train.p\", \"rb\" ))\n",
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"labels.p\", \"rb\" ))\n",
    "\n",
    "# Make into arrays as the neural network wants these\n",
    "#train_images = np.array(train_images)\n",
    "#labels = np.array(labels)\n",
    "\n",
    "\n",
    "augmented_images, augmented_labels=[],[]\n",
    "for image,label in zip(train_images,labels):\n",
    "    augmented_images.append(np.array(image))\n",
    "    augmented_labels.append(np.array(label))\n",
    "    augmented_images.append(np.array(cv2.flip(image,1)))\n",
    "    augmented_labels.append(np.expand_dims(np.array(cv2.flip(label,1)),axis=2))\n",
    "\n",
    "augmented_images=np.array(augmented_images)\n",
    "augmented_labels=np.array(augmented_labels)\n",
    "\n",
    "\n",
    "# Normalize labels - training images get normalized to start in the network\n",
    "augmented_labels = augmented_labels / 255\n",
    "\n",
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "augmented_images, augmented_labels = shuffle(augmented_images, augmented_labels)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(augmented_images, augmented_labels, test_size=0.05)\n",
    "\n",
    "# Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "batch_size = 128\n",
    "epochs = 3\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "### Here is the actual neural network ###\n",
    "model = Sequential()\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# Below layers were re-named for easier reading of model summary; this not necessary\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "# Pooling 1\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv Layer 5\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Pooling 2\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Conv Layer 6\n",
    "model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv Layer 7\n",
    "model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Pooling 3\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Upsample 1\n",
    "model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "# Deconv 1\n",
    "model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Deconv 2\n",
    "model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Upsample 2\n",
    "model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "# Deconv 3\n",
    "model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Deconv 4\n",
    "model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Deconv 5\n",
    "model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Upsample 3\n",
    "model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "# Deconv 6\n",
    "model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "# Final layer - only including one channel so 1 filter\n",
    "model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "### End of network ###\n",
    "\n",
    "\n",
    "# Using a generator to help the model use less data\n",
    "# Channel shifts help with shadows slightly\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "# Save model architecture and weights\n",
    "model.save('full_CNN_model.h5')\n",
    "\n",
    "# Show summary of model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'insert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5534356b5b8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'insert'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'augmented_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0d022b3dd002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'augmented_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print(augmented_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2681, 80, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
